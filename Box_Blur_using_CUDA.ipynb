{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFFDG89Xv9yF",
        "outputId": "a340f581-e846-4c86-ca07-65b78d5f41fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79r5GIMrwQ4G",
        "outputId": "0cf13e03-4e0d-4d2d-de6b-6cbc89d701fb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-xb_tfi3b\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-xb_tfi3b\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 28f872a2f99a1b201bcd0db14fdbc5a496b9bfd7\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: nvcc4jupyter\n",
            "  Building wheel for nvcc4jupyter (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvcc4jupyter: filename=nvcc4jupyter-1.2.1-py3-none-any.whl size=10743 sha256=3a570d3ab74e9051a615aa78d54722c78a69a0c83a1d407fccde14c37a30e96c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-t6o48f7q/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built nvcc4jupyter\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nvcc4jupyter\n",
        "%load_ext nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWhpyibswQWn",
        "outputId": "3873d2e6-b628-493b-c316-d6c4ae772d8d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nvcc4jupyter in /usr/local/lib/python3.10/dist-packages (1.2.1)\n",
            "Detected platform \"Colab\". Running its setup...\n",
            "Source files will be saved in \"/tmp/tmpe7vtn56b\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXk4qqbmwdez",
        "outputId": "03a0182f-47ba-45bc-fd4b-ff998f9f17ce"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Oct 18 08:32:43 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the code into a .cu file\n",
        "%%writefile blur_cuda.cu\n",
        "\n",
        "#include \"lodepng.h\"\n",
        "#include <cuda_runtime.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void boxBlurKernel(unsigned char* d_image, unsigned char* d_output, int width, int height) {\n",
        "    int x = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int y = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\n",
        "    // Check if the pixel is within bounds\n",
        "    if (x < width && y < height) {\n",
        "        int redSum = 0, greenSum = 0, blueSum = 0;\n",
        "        int count = 0;\n",
        "\n",
        "        // Iterate over 3x3 neighborhood\n",
        "        for (int i = -1; i <= 1; ++i) {\n",
        "            for (int j = -1; j <= 1; ++j) {\n",
        "                int nx = x + i;\n",
        "                int ny = y + j;\n",
        "\n",
        "                // Check if neighbor coordinates are within bounds\n",
        "                if (nx >= 0 && ny >= 0 && nx < width && ny < height) {\n",
        "                    int idx = 4 * (ny * width + nx);\n",
        "                    redSum += d_image[idx];\n",
        "                    greenSum += d_image[idx + 1];\n",
        "                    blueSum += d_image[idx + 2];\n",
        "                    count++;\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "\n",
        "        // Calculate the new blurred pixel value\n",
        "        int outIdx = 4 * (y * width + x);\n",
        "        d_output[outIdx] = redSum / count;\n",
        "        d_output[outIdx + 1] = greenSum / count;\n",
        "        d_output[outIdx + 2] = blueSum / count;\n",
        "        d_output[outIdx + 3] = d_image[outIdx + 3];  // Copy alpha unchanged\n",
        "    }\n",
        "}\n",
        "\n",
        "void checkCudaError(cudaError_t err, const char *msg) {\n",
        "    if (err != cudaSuccess) {\n",
        "        printf(\"CUDA Error: %s: %s\\n\", msg, cudaGetErrorString(err));\n",
        "        exit(1);\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    // Read the PNG file into an image array\n",
        "    unsigned char* image;\n",
        "    unsigned width, height;\n",
        "    unsigned error = lodepng_decode32_file(&image, &width, &height, \"input.png\");\n",
        "\n",
        "    if (error) {\n",
        "        printf(\"Error decoding PNG: %s\\n\", lodepng_error_text(error));\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    // Allocate GPU memory\n",
        "    unsigned char* d_image;\n",
        "    unsigned char* d_output;\n",
        "    size_t imageSize = width * height * 4;\n",
        "    checkCudaError(cudaMalloc(&d_image, imageSize), \"Allocating d_image\");\n",
        "    checkCudaError(cudaMalloc(&d_output, imageSize), \"Allocating d_output\");\n",
        "\n",
        "    // Copy image data to GPU\n",
        "    checkCudaError(cudaMemcpy(d_image, image, imageSize, cudaMemcpyHostToDevice), \"Copying image to d_image\");\n",
        "\n",
        "    // Define block and grid sizes\n",
        "    dim3 blockSize(16, 16);\n",
        "    dim3 gridSize((width + blockSize.x - 1) / blockSize.x, (height + blockSize.y - 1) / blockSize.y);\n",
        "\n",
        "    // Apply the box blur kernel\n",
        "    boxBlurKernel<<<gridSize, blockSize>>>(d_image, d_output, width, height);\n",
        "    cudaDeviceSynchronize(); // Ensure the kernel has finished\n",
        "\n",
        "    // Check for any errors during kernel execution\n",
        "    checkCudaError(cudaGetLastError(), \"Running boxBlurKernel\");\n",
        "\n",
        "    // Copy blurred image data back to the CPU\n",
        "    checkCudaError(cudaMemcpy(image, d_output, imageSize, cudaMemcpyDeviceToHost), \"Copying d_output to image\");\n",
        "\n",
        "    // Write the blurred image to a file\n",
        "    error = lodepng_encode32_file(\"output_blur.png\", image, width, height);\n",
        "    if (error) {\n",
        "        printf(\"Error encoding PNG: %s\\n\", lodepng_error_text(error));\n",
        "    }\n",
        "\n",
        "    // Free memory\n",
        "    cudaFree(d_image);\n",
        "    cudaFree(d_output);\n",
        "    free(image);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIpDhKpbwf1x",
        "outputId": "ef309bcf-8f2a-4015-84c2-e68cf66cf27b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing blur_cuda.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o blur_cuda blur_cuda.cu lodepng.cpp\n",
        "\n"
      ],
      "metadata": {
        "id": "43cY7jyPwuEm"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./blur_cuda\n"
      ],
      "metadata": {
        "id": "xv4DfgCpxiRP"
      },
      "execution_count": 21,
      "outputs": []
    }
  ]
}